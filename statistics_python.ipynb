{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**  \n",
    "Here I present useful python snippets to use for statistical calculations. \n",
    "I also add the relevant equations and sometime relevant examples to explain usage.  \n",
    "The content is aimed for the advanced practitioner that needs a quick reminder.  \n",
    "\n",
    "\n",
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinatorics\n",
    "\n",
    "## Permutations \n",
    "When order matters\n",
    "\n",
    "An ordered arrangement of $k$ objects from a set of $n$\n",
    "\n",
    "$$\n",
    "_nP_k=\\frac{n!}{(n-k)!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T10:34:17.199450Z",
     "start_time": "2020-03-20T10:34:17.189851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2432902008176640000\n",
      "2432902008176640000\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "\n",
    "def simplistic_factorial(n):\n",
    "    assert isinstance(n, int)\n",
    "    \n",
    "    if n == 0:\n",
    "        return 1\n",
    "    \n",
    "    factor = simplistic_factorial(n-1)\n",
    "    \n",
    "    return factor * n\n",
    "    \n",
    "k = 20\n",
    "\n",
    "print(factorial(k))\n",
    "print(simplistic_factorial(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T15:03:21.555751Z",
     "start_time": "2020-03-18T15:03:21.539696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 6\n",
    "k = 2\n",
    "\n",
    "int(factorial(n)/factorial(n - k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:58:46.957026Z",
     "start_time": "2020-03-18T14:58:46.950210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]\n",
      "[(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n",
      "[(1, 1), (1, 3), (1, 1), (1, 3), (3, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations \n",
    "\n",
    "\n",
    "# All permutations of [1, 2, 3] \n",
    "print(list(permutations([1, 2, 3])))\n",
    "\n",
    "# All permutations of pairs consisting of [1, 2, 3] \n",
    "print(list(permutations([1, 2, 3], 2)))\n",
    "\n",
    "# All permutations of pairs consisting of [1, 1, 3] \n",
    "print(list(permutations([1, 1, 3], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations\n",
    "When order does not matter\n",
    "\n",
    "An unordered arrangement of $k$ objects from a set of $n$\n",
    "$$\n",
    "_nC_k=\\frac{n!}{(n-k)!k!}\\equiv {n \\choose k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:59:01.141849Z",
     "start_time": "2020-03-18T14:59:00.887495Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:59:02.847045Z",
     "start_time": "2020-03-18T14:59:02.839818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "k = 2\n",
    "\n",
    "print(int(factorial(n)/factorial(k)/factorial(n-k)))\n",
    "print(int(comb(n, k, repetition=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:59:15.426666Z",
     "start_time": "2020-03-18T14:59:15.421751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (1, 3), (2, 3)]\n",
      "[(1, 1), (1, 3), (1, 3)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations \n",
    "\n",
    "# All combinations of pairs consisting of [1, 2, 3] \n",
    "print(list(combinations([1, 2, 3], 2)))\n",
    "# All combinations of pairs consisting of [1, 1, 3] \n",
    "print(list(combinations([1, 1, 3], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Random Variables\n",
    "\n",
    "## Variance\n",
    "\n",
    "For descrete variables\n",
    "$$\n",
    "\\text{Var}(X) = \\text{E}[(X-\\text{E}[X])^2] = \\text{E}[X^2] - \\text{E}[X]^2\n",
    "$$\n",
    "\n",
    "## Standard Deviation \n",
    "A measure of the amount of variation or dispersion of a set of values.  \n",
    "**Population Standard Deviation**\n",
    "$$\n",
    "S = \\sqrt{ \\frac{\\sum_i^N \\left(X_i-\\bar{X} \\right)^2}{N}}\n",
    "$$\n",
    "**Sample Standard Deviation** (Estimator)   \n",
    "The following is the unbiased estimator if the variance exists and the sample values are drawn independently **with replacement**. There are $N-1$ degrees of freedom (because of the dependence on $\\bar{X}$). \n",
    "$$\n",
    "S = \\sqrt{ \\frac{\\sum_i^N \\left(X_i-\\bar{X} \\right)^2}{N-1}}\n",
    "$$\n",
    "$S^2$ is the unbiased estimator of the **population variance**, though $S$ is still a biased estimator for the **population standard deviation**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:28:26.127644Z",
     "start_time": "2020-03-23T09:28:26.117949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 6.730000000000001, 6.73\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "xs = [10.0, 9.8, 8.0, 7.8, 7.7, 7.0, 6.0, 5.0, 4.0, 2.0]\n",
    "\n",
    "# --- Mean ---\n",
    "mean_ = sum(xs)/len(xs)\n",
    "\n",
    "print(f'mean: {mean_}, {mean(xs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:31:33.880334Z",
     "start_time": "2020-03-23T09:31:33.873383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population variance: 5.724100000000002, 5.724100000000001\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, pvariance\n",
    "\n",
    "xs = [10.0, 9.8, 8.0, 7.8, 7.7, 7.0, 6.0, 5.0, 4.0, 2.0]\n",
    "\n",
    "def sum_squares(l):\n",
    "    mean_ = mean(l)\n",
    "    return sum([(l[idx] - mean_)**2 for idx in range(len(l))])\n",
    "\n",
    "def simple_pvariance(l):\n",
    "    dof = len(l)\n",
    "        \n",
    "    return sum_squares(l)/dof\n",
    "\n",
    "print(f'population variance: {simple_pvariance(xs)}, {pvariance(xs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:37:46.467684Z",
     "start_time": "2020-03-23T09:37:46.459379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample variance: 6.360111111111113, 6.360111111111111\n",
      "sample standard deviation: 2.5219260716981995, 2.5219260716981995\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, variance, stdev\n",
    "\n",
    "def simple_variance(l):\n",
    "    dof = len(l) - 1\n",
    "    return sum_squares(l)/dof\n",
    "\n",
    "print(f'sample variance: {simple_variance(xs)}, {variance(xs)}')\n",
    "print(f'sample standard deviation: {simple_variance(xs)**0.5}, {stdev(xs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "A measure of how two random variables change together, or the strength of their correlation.\n",
    "\n",
    "$$\n",
    "\\text{cov}(X,Y) = \\text{E}\\left[ \\left(X - \\text{E}[X] \\right)\\left(Y - \\text{E}[Y] \\right) \\right]  =  \\text{E}[XY] - \\text{E}[X]\\text{E}[Y] =\\\\ \n",
    "\\frac{1}{N}\\sum_{i=1}^N\\left(X_i - \\bar{X}\\right)\\left(Y_i - \\bar{Y}\\right)\n",
    "$$\n",
    "\n",
    "## Pearson Correlation Coefficient\n",
    "\n",
    "$$\n",
    "\\rho_{X,Y} = \\frac{\\text{cov}(X,Y)}{\\sigma_X\\sigma_Y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:04.064316Z",
     "start_time": "2020-03-23T09:42:04.056544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson R: 0.612472193720848,  0.6124721937208482\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, pvariance\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "xs = [10.0, 9.8, 8.0, 7.8, 7.7, 7.0, 6.0, 5.0, 4.0, 2.0]\n",
    "ys = [200.0, 44.0, 32.0, 24.0, 22.0, 17.0, 15.0, 12.0, 8.0, 4.0]\n",
    "\n",
    "mean_x = mean(xs)\n",
    "mean_y = mean(ys)\n",
    "\n",
    "cov_xy = sum([(xs[idx] - mean_x) * (ys[idx] - mean_y) for idx in range(len(xs))]) / len(xs)\n",
    "std_x = pvariance(xs) ** 0.5\n",
    "std_y = pvariance(ys) ** 0.5\n",
    "\n",
    "\n",
    "pearsonr_ = cov_xy / std_x/ std_y\n",
    "\n",
    "print(f'Pearson R: {pearsonr_},  {pearsonr(xs, ys)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T08:37:59.923753Z",
     "start_time": "2020-03-23T08:37:59.917779Z"
    }
   },
   "source": [
    "## Spearman's Rank Correlation Coefficient\n",
    "\n",
    "\n",
    "Special case where $X$ and $Y$  don't contain duplicates\n",
    "$$\n",
    "\\rho_s = 1 - \\frac{6 \\sum_{i=1}^N d_i^2}{n(n^2-1)}\n",
    "$$\n",
    "\n",
    "$d_i=\\text{Rank}(X_i) - \\text{Rank}(Y_i)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:13:31.792054Z",
     "start_time": "2020-03-23T10:13:31.779434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman R: 0.9030303030303031, 0.9030303030303028\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "xs = [10, 9.8, 8, 7.8, 7.7, 1.7, 6, 5, 1.4, 2]\n",
    "ys = [200, 44, 32, 24, 22, 17, 15, 12, 8, 4]\n",
    "\n",
    "def rank_list(l):\n",
    "    n = len(l)\n",
    "    ranks = [None] * n\n",
    "    indices = list(range(len(l)))\n",
    "    indices.sort(key=lambda x: l[x])\n",
    "    for rank, idx in enumerate(indices):\n",
    "        ranks[idx] = rank + 1\n",
    "        \n",
    "    return ranks\n",
    "\n",
    "def simple_spearman(xs, ys):\n",
    "    xs_ranks = rank_list(xs)\n",
    "    ys_ranks = rank_list(ys)\n",
    "\n",
    "    n = len(xs)\n",
    "    d2 = sum([(xs_ranks[idx] - ys_ranks[idx])**2 for idx in range(n)])\n",
    "\n",
    "    return 1 - 6 * d2/n/(n**2-1)\n",
    "\n",
    "print(f'Spearman R: {simple_spearman(xs, ys)}, {spearmanr(xs, ys)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "If $X_1 , X_2 , ... , X_n$ is a random sample of size n taken from a population (either finite or infinite) with mean $\\mu$ and finite variance $\\sigma^2$ and if $\\bar{X}$ is the sample mean, the limiting form of the distribution of \n",
    "\n",
    "$$\n",
    "Z=\\left({\\frac {{\\bar {X}}-\\mu }{\\sigma /\\surd n}}\\right)\n",
    "$$ as n → ∞, is the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:42:01.366552Z",
     "start_time": "2020-03-22T08:42:01.360864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 100 items with mu=500 and sigma=80\n",
      "95% of the values are between 484.32 and 515.68 (using z*=1.96)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "n = 100   # for n items\n",
    "mu = 500  # with mean mu\n",
    "sigma = 80 # and std sigma\n",
    "z = 1.96\n",
    "\n",
    "sigma_ = sigma/sqrt(n)\n",
    "low_ = round(mu - z * sigma_,2)\n",
    "high_ = round(mu + z * sigma_,2)\n",
    "\n",
    "print(fr'for {n} items with mu={mu} and sigma={sigma}')\n",
    "print(f'95% of the values are between {low_} and {high_} (using z*={z})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:47:24.732340Z",
     "start_time": "2020-03-22T08:47:24.722892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 100 items with mu=50 and sigma=10\n",
      "there is a 84.1% chance of having sum at value 5100.0\n"
     ]
    }
   ],
   "source": [
    "from math import erf, sqrt\n",
    "\n",
    "def phi(x):\n",
    "    'Cumulative distribution function for the standard normal distribution'\n",
    "    return (1.0 + erf(x / sqrt(2.0))) / 2.0\n",
    "\n",
    "def cumulative_norm(x, mu=0, sigma=1):\n",
    "    z = (x-mu)/sigma\n",
    "    \n",
    "    return phi(z)\n",
    "\n",
    "n = 100   # for n items\n",
    "mu = 50 # with mean mu\n",
    "sigma = 10 # and std sigma\n",
    "x = mu * n + sigma * sqrt(n)\n",
    "\n",
    "mu_ = mu * n\n",
    "sigma_ = sigma * sqrt(n)\n",
    "prob = cumulative_norm(x, mu_, sigma_)\n",
    "\n",
    "print(f'for {n} items with mu={mu} and sigma={sigma}')\n",
    "print(f'there is a {prob*100:0.1f}% chance of having sum at value {x:0.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy \n",
    "(or Self Information for a Random Variable)  \n",
    "A measure of uncertainty of events. \n",
    "\n",
    "\n",
    "Given a random variable $X$, with possible outcomes $x_{i}$, each with probability $p_{X}(x_{i})$, the entropy $H(X)$ of $X$ is  \n",
    "\n",
    "$$\n",
    "H(X) = - \\Sigma_{x_i} p_X(x_i) \\text{log}_b p_X(x_i)\n",
    "$$\n",
    "\n",
    "$b$ - base of logarithm\n",
    "\n",
    "**Shannon Information Content / Self Information**  \n",
    "The above is derived from the notion that $log_2(p)$ is the amount of information (in bits) a message is communicating. \n",
    "\n",
    "\n",
    "The number of bits to describe the probability of event $A$ happening is \n",
    "$$\n",
    "log_2\\left(\\frac{1}{P(A)}\\right)\n",
    "$$\n",
    "\n",
    "Another interpretation: how surprised should we be when seeing event $A$.  \n",
    "E.g, large $P(A)$ we are lesss surprised, small $P(A)$ more surprised. \n",
    "\n",
    " \n",
    "* **Entropy** - the average amount of useful information. Or the expecation of the Shannon information content $H(x)=E\\left[log\\left(\\frac{1}{p_X(x)}\\right)\\right]$.  \n",
    "* **Cross Entropy** - the average length of a message. In ML commonly used as a cost function in classifiers.   \n",
    "* **Kullback-Leibler Divergence** (also *relative entropy*, or *information divergence*) - the difference between cross-entropy and entropy\n",
    "\n",
    "If the predictions are close to the truth, the cross entropy is similar to the entropy (low KL divergence).\n",
    "\n",
    "If the predictions differ, then the cross-entropy will be greater in terms of bits (high KL divergence)\n",
    "\n",
    "$$\n",
    "\\text{Cross Entropy} = \\text{Entropy} + \\text{KL Divergence}\n",
    "$$\n",
    "\n",
    "From Bayesian Inference:  \n",
    "KL Divergence is a measure of the information gained when one revises one's beliefs from the prior probability distribution Q to the posterior probability distribution P. -- Or -- the amount of information lost when Q is used to approximate P. In applications, P typically represents the \"true\" distribution of data, observations or a precisely calculated theoretical distribution, while Q typically represents a theory, model, description, or approximation of P. In order to find a distribution Q that is closest to P, we can minimize KL divergence and compute an information projection. \n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}\\left(P||Q \\right) = H(P,Q) - H(P) = - \\Sigma p(x) \\text{log} q(x) + \\Sigma p(x) \\text{log} p(x) = E_{X\\sim p}\\left[log\\left(\\frac{p(x)}{q(x)}\\right)\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Note that $D_{\\text{KL}} \\ge 0$ due to the fact that $H(P,Q) \\ge H(P)$.  \n",
    "In information theory $D_{\\text{KL}}\\left(P||Q \\right)$ is the average penalty for storing a sample from $p$ using distribution $q$ instead of distribution $p$.  \n",
    "\n",
    "**Resources**  \n",
    "* A Short Introduction to Entropy, Cross-Entropy and KL-Divergence / Aurélien Géron ([YouTube](https://www.youtube.com/watch?v=ErfnhcEV1O8))  \n",
    "* Computational Probability and Inference (Week 4) ([edX/MIT](https://www.edx.org/course/computational-probability-and-inference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sun': 0.75, 'rain': 0.25} means that\n",
      "a sun notice reduces the outcome uncertainty by 1.333 and hence 0.415 bit(s) of information\n",
      "a rain notice reduces the outcome uncertainty by 4.0 and hence 2.0 bit(s) of information\n",
      "yielding an average message of length 0.811 bit(s)\n"
     ]
    }
   ],
   "source": [
    "# entropy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#p = {'sun': 0.5, 'rain': 0.5}    # entropy: 1\n",
    "p = {'sun': 0.75, 'rain': 0.25}   # entropy: 0.811\n",
    "#p = {'sun': 0.99, 'rain': 0.01}  # entropy: 0.81\n",
    "\n",
    "station_notice = 'sun'\n",
    "print(f'{p} means that\\na {station_notice} notice reduces the outcome uncertainty by {np.round(1./p[station_notice],3)} and hence {np.round(-np.log(p[station_notice])/np.log(2),3)} bit(s) of information')\n",
    "station_notice = 'rain'\n",
    "print(f'a {station_notice} notice reduces the outcome uncertainty by {np.round(1./p[station_notice],3)} and hence {np.round(-np.log(p[station_notice])/np.log(2),3)} bit(s) of information')\n",
    "\n",
    "\n",
    "h = 0\n",
    "for station_notice in p.keys():\n",
    "    h -= p[station_notice] * np.log(p[station_notice])\n",
    "h /= np.log(2)\n",
    "print(f'yielding an average message of length {np.round(h,3)} bit(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:58:57.457969Z",
     "start_time": "2020-03-22T11:58:57.431000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In base e\n",
      "0.6931471805599453\n",
      "0.6931471805599453\n",
      "In Shannons (base 2)\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "# fair coin\n",
    "pxs = [0.5, 0.5]  # 50% tails, 50% heads\n",
    "\n",
    "h = 0\n",
    "for px in pxs:\n",
    "    h -= px * np.log(px)\n",
    "\n",
    "print('In base e')\n",
    "print(h)\n",
    "print(entropy(pxs))\n",
    "\n",
    "print('In Shannons (base 2)')\n",
    "print(h/np.log(2))\n",
    "print(entropy(pxs, base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:57:38.363510Z",
     "start_time": "2020-03-22T11:57:38.357650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "# fair die (higher entropy than fair coin!)\n",
    "pxs = [1./6] * 6\n",
    "\n",
    "print(entropy(pxs, base=2)) # Shannons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true      distribution: [0.35, 0.35, 0.1, 0.1, 0.04, 0.04, 0.01, 0.01]\n",
      "predicted distribution [0.25, 0.25, 0.125, 0.125, 0.0625, 0.0625, 0.03125, 0.03125]\n",
      "entropy: 2.229\n",
      "cross-entropy (naive):       3.0  (kl=0.771 bits)\n",
      "cross-entropy (modified):       2.42  (kl=0.191 bits)\n",
      "cross-entropy (true):       2.229\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cross entropy and KL-divergence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p_uniform = [1/8. for i in range(8)]\n",
    "p_non_uniform = [35./100, 35./100, 0.1, 0.1, 0.04, 0.04, 0.01, 0.01]\n",
    "p_non_uniform_reverse = p_non_uniform[::-1]\n",
    "\n",
    "# --- true distribution --\n",
    "ps = p_uniform\n",
    "ps = p_non_uniform\n",
    "#ps = p_non_uniform_reverse\n",
    "\n",
    "h = entropy(ps, base=2)\n",
    "\n",
    "bits_per_event = [-np.log(p)/np.log(2) for p in ps]\n",
    "\n",
    "# --- predicted distribution --\n",
    "bits_per_event_predicted = [2, 2, 3, 3, 4, 4, 5, 5]\n",
    "q_predicted_distribution = [1./2**(event_bits) for event_bits in bits_per_event_predicted]\n",
    "\n",
    "print(f'true      distribution: {ps}')\n",
    "print(f'predicted distribution {q_predicted_distribution}')\n",
    "\n",
    "cross_entropy, cross_entropy_incorrect, cross_entropy_modified = 0, 0,0 \n",
    "for p, event_bits, event_bits_predicted in zip(ps, bits_per_event, bits_per_event_predicted):\n",
    "    cross_entropy += p * event_bits\n",
    "    cross_entropy_incorrect += p * 3.\n",
    "    cross_entropy_modified += p * event_bits_predicted\n",
    "    \n",
    "kl_incorrect = cross_entropy_incorrect - h\n",
    "kl_modified = cross_entropy_modified - h\n",
    "    \n",
    "print(f'entropy: {np.round(h,3)}\\ncross-entropy (naive): \\\n",
    "      {np.round(cross_entropy_incorrect,3)}  (kl={np.round(kl_incorrect,3)} bits)\\ncross-entropy (modified): \\\n",
    "      {np.round(cross_entropy_modified,3)}  (kl={np.round(kl_modified,3)} bits)\\ncross-entropy (true): \\\n",
    "      {np.round(cross_entropy,3)}') \n",
    "\n",
    "\n",
    "xs = np.arange(len(ps))\n",
    "\n",
    "width = 0.3\n",
    "plt.bar(xs, ps, color='green', alpha=0.7, width=width)\n",
    "plt.bar(xs + width, q_predicted_distribution, color='blue', alpha=0.7, width=width)\n",
    "plt.title(f'H(p)={np.round(h,2)}, H(p,q)={np.round(cross_entropy_modified,2)}, KL(p|q)={np.round(kl_modified,2)}')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities\n",
    "\n",
    "## Probability Spaces and Events\n",
    "\n",
    "**Outcome** - A result of an experiment. All possible outcomes comprise a set $\\Omega$, where $\\sum_{\\omega \\in \\Omega} P(\\omega)=1$\n",
    "\n",
    "**Event** - a set of one or more experiment outcomes $\\Omega$, i.e, a subset of $\\Omega$.   \n",
    "Example:  \n",
    "An experiment of flipping two coins has four outcomes: $\\Omega$=`{HH, HT, TH, TT}`.   \n",
    "Example events are:  \n",
    "* Occurences in which the second coin has tails: `A={HT, TT}`$\\subset \\Omega$  \n",
    "* Occurences in which there is at least one heads: `B={HH, HT, TH}`\n",
    "* Occurance in which both are heads `C={HH}`\n",
    "\n",
    "Note: When you run an experiment, there can be only one outcome, but there can be multiple events.  E.g if the experiment yields outcome `HT`, events `A` and `B` have occured simultaneously.   \n",
    "\n",
    "*Event compliment*  \n",
    "$A^c = \\forall \\omega \\notin A$  \n",
    "$\\phi \\notin \\Omega$ is the empty set.  \n",
    "$A \\cap C = \\phi$ means there is no overlap (as in the example above).\n",
    "\n",
    "Suggestion:  \n",
    "It is better of thinking about probability of an event rather than an outcome. E.g, in the case of an event with one outcome $\\omega$, it would be better to discuss $P(\\{\\omega\\})$ than $P(\\omega)$.  \n",
    "\n",
    "\n",
    "\n",
    "$P(A)=\\sum_{\\omega \\in A} P(\\omega)$ - Marginal Probability of event $A$\n",
    "\n",
    "$P(A) + P(A^c) = P(\\Omega) \\equiv 1$  \n",
    "$P(\\phi) = 0 $  \n",
    "\n",
    "if $A \\subset B$ then $P(A) \\le P(B)$\n",
    "\n",
    "\n",
    "## Events as r.v\n",
    "\n",
    "Given $(\\Omega, P)$   \n",
    "r.v $X: \\Omega \\rightarrow \\mathcal{X}$  \n",
    "\n",
    "$\\Omega$ - sample space  \n",
    "$P$ - probability distribution  \n",
    "$\\mathcal{X}$ - alphabet: set of values of r.v that $X$ takes.   \n",
    "\n",
    "\n",
    "E.g,  \n",
    "$W(\\omega)=$ `{sun, rain, snow}`  \n",
    "$I(\\omega) \\begin{cases} 1 \\ \\ \\text{if} \\ \\omega\\in\\{\\text{sun} \\}  \\\\ 0 \\ \\  \\text{if} \\ \\omega\\in\\{\\text{rain, snow}  \\}  \\end{cases}$  \n",
    "We see:  \n",
    "$W: \\Omega \\rightarrow \\Omega$, or $\\mathcal{W} = \\Omega$  \n",
    "$I: \\Omega \\rightarrow \\{0, 1\\}$, or $\\mathcal{I} = \\{0, 1 \\}$ \n",
    "\n",
    "**Probability Mass Function** (pmf)    \n",
    "Also called: probability table and probability distribution.  \n",
    "From a r.v $X$ we define a probability $P_{X}=\\mathbb{P}(X=x)$, where $x\\in\\mathcal{X}$  \n",
    "\n",
    "$0\\le P_X \\le 1$  \n",
    "$\\sum_{x\\in \\mathcal{X}}P_X(x)= 1$\n",
    "\n",
    "\n",
    "E.g,  \n",
    "$P_{W}(w) = \\mathbb{P}(W=w)$  \n",
    "$P_{I}(i) = \\mathbb{P}(I=i)$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T08:04:14.891207Z",
     "start_time": "2020-04-18T08:04:14.885183Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_from_finite_probability_space(finite_prob_space):\n",
    "    \"\"\"\n",
    "    Produces a random outcome from a given finite probability space.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    - finite_prob_space: finite probability space encoded as a\n",
    "      dictionary\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    - random outcome, which is one of the keys in the\n",
    "      finite_probability_space dictionary's set of keys\n",
    "      (remember: these keys form the sample space)\n",
    "    \"\"\"\n",
    "\n",
    "    # first produce a list of pairs of the form (outcome, outcome probability)\n",
    "    outcome_probability_pairs = list(finite_prob_space.items())\n",
    "\n",
    "    # convert the pairs into two lists \"outcomes\" and \"outcome_probabilities\":\n",
    "    # - outcomes: list of outcomes\n",
    "    # - outcome_probabilities: i-th element is the probability of the i-th\n",
    "    #   outcome in the \"outcomes\" list\n",
    "    # (note that this step is needed because NumPy wants these lists\n",
    "    # separately)\n",
    "    outcomes, outcome_probabilities = zip(*outcome_probability_pairs)\n",
    "\n",
    "    # use NumPy to randomly sample\n",
    "    random_outcome = np.random.choice(outcomes, p=outcome_probabilities)\n",
    "    return random_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T08:12:31.674852Z",
     "start_time": "2020-04-18T08:12:31.669158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome=sunny, i.e,\n",
      "W=sunny, I=1\n"
     ]
    }
   ],
   "source": [
    "# Approach 1\n",
    "\n",
    "prob_space = {'sunny': 1/2, 'rainy': 1/6, 'snowy': 1/3}\n",
    "\n",
    "W_mapping = {'sunny': 'sunny', 'rainy': 'rainy', 'snowy': 'snowy'}\n",
    "I_mapping = {'sunny': 1, 'rainy': 0, 'snowy': 0}\n",
    "\n",
    "\n",
    "random_outcome = sample_from_finite_probability_space(prob_space)\n",
    "random_outcome\n",
    "\n",
    "W = W_mapping[random_outcome]\n",
    "I = I_mapping[random_outcome]\n",
    "\n",
    "print(f'outcome={random_outcome}, i.e,\\nW={W}, I={I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T08:12:19.698717Z",
     "start_time": "2020-04-18T08:12:19.693062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sun': 0.5, 'rain': 0.16666666666666666, 'snow': 0.3333333333333333} {0: 0.5, 1: 0.5}\n",
      "W = snow\n",
      "I=0  (need not be same as W=snow)\n"
     ]
    }
   ],
   "source": [
    "# Approach 2\n",
    "\n",
    "W_table = {'sun': 0.5, 'rain': 1./6, 'snow': 1/3.}\n",
    "I_table = {0: 0.5, 1: 0.5}\n",
    "\n",
    "print(W_table, I_table)\n",
    "\n",
    "W = sample_from_finite_probability_space(W_table)\n",
    "I = sample_from_finite_probability_space(I_table)\n",
    "\n",
    "print(f'W = {W}')\n",
    "print(f'I={I}  (need not be same as W={W})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relating Two Events\n",
    "\n",
    "**Compound event**  \n",
    "combination of 2 or more events  \n",
    "\n",
    "$P(A|B)$ - Conditional Probability (of $A$ happening given $B$ occured)  \n",
    "\n",
    "*Intersect of events* $A\\cap B$  \n",
    "$P(A\\cap B)\\equiv P(A, B)$ - Joint Probability of events $A$ and $B$ ( `and` rule - think Venn Diagram)     \n",
    "$P(A\\cap B) = P(A|B)P(B)$ - Chain rule (Product Rule)  \n",
    "$$\n",
    " P(A|B) = \\frac{P(A\\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "*Union of events*  $A\\cup B$   \n",
    "$P(A\\cup B) = P(A) + P(B) - P(A\\cap B)$  (`or` rule - think Venn Diagram)\n",
    "\n",
    "**Event Relationships**  \n",
    "$P(A|B) = P(A)$ - When $A$ is *independent* of $B$.  \n",
    "$P(A \\cup B) = P(A)+P(B)$ - When $A$ and $B$ are *disjoint* events ($P(A\\cap B)=0$)    \n",
    "$P(A \\cup B)=1$ - When $A$ and $B$ are *mutually exhaustive*  \n",
    "\n",
    "**Bayes' Theorem**  \n",
    "(Bayes' Rule, Bayes' Law)  \n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)} = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)}\n",
    "$$\n",
    "\n",
    "Model form:  \n",
    "$$\n",
    "P(\\Theta|\\text{data}) = \\frac{P(\\text{data}|\\Theta)P(\\Theta)}{P(\\text{data})}\n",
    "$$\n",
    "\n",
    "\n",
    "$P(\\Theta|\\text{data})$ - posterior distribution of parameters $\\Theta$ given `data` has been observed    \n",
    "$P(\\Theta)$ - prior distribution of parameters $\\Theta$   \n",
    "$P(\\text{data}|\\Theta)$ - the likelihood distribution $L(\\text{data})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:11:52.636329Z",
     "start_time": "2020-04-18T09:11:52.630572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(w=sunny,t=cold)=0.2\n"
     ]
    }
   ],
   "source": [
    "# Approach 0: All values\n",
    "\n",
    "prob_table = {('sunny', 'hot'): 3/10,\n",
    "    ('sunny', 'cold'): 1/5,\n",
    "    ('rainy', 'hot'): 1/30,\n",
    "    ('rainy', 'cold'): 2/15,\n",
    "    ('snowy', 'hot'): 0,\n",
    "    ('snowy', 'cold'): 1/3}\n",
    "\n",
    "w = 'sunny'\n",
    "t = 'cold'\n",
    "print(f'p(w={w},t={t})={prob_table[(w, t)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:12:15.445456Z",
     "start_time": "2020-04-18T09:12:15.434082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            hot      cold\n",
      "rainy  0.033333  0.133333\n",
      "snowy  0.000000  0.333333\n",
      "sunny  0.300000  0.200000\n",
      "\n",
      "p(w=sunny,t=cold)=0.2\n"
     ]
    }
   ],
   "source": [
    "# Approach 1: Joint distribution using dictionaries within a dictionary\n",
    "import pandas as pd\n",
    "\n",
    "def print_joint_prob_table_dict(dicts_in_dict):\n",
    "    \"\"\"\n",
    "    Prints a joint probability table that is stored using the dictionaries\n",
    "    within a dictionary representation.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    - dicts_in_dict: joint probability table stored as dictionaries within a\n",
    "      dictionary\n",
    "    \"\"\"\n",
    "    print(pd.DataFrame(dicts_in_dict).T)\n",
    "\n",
    "prob_W_T_dict = {}\n",
    "for w in {'sunny', 'rainy', 'snowy'}:\n",
    "    prob_W_T_dict[w] = {}\n",
    "\n",
    "prob_W_T_dict['sunny']['hot'] = 3/10\n",
    "prob_W_T_dict['sunny']['cold'] = 1/5\n",
    "prob_W_T_dict['rainy']['hot'] = 1/30\n",
    "prob_W_T_dict['rainy']['cold'] = 2/15\n",
    "prob_W_T_dict['snowy']['hot'] = 0\n",
    "prob_W_T_dict['snowy']['cold'] = 1/3\n",
    "\n",
    "print_joint_prob_table_dict(prob_W_T_dict)\n",
    "\n",
    "print(f'\\np(w={w},t={t})={prob_W_T_dict[w][t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:22:46.320468Z",
     "start_time": "2020-04-18T09:22:46.308250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3        0.2       ]\n",
      " [0.03333333 0.13333333]\n",
      " [0.         0.33333333]] \n",
      "\n",
      "            hot      cold\n",
      "sunny  0.300000  0.200000\n",
      "rainy  0.033333  0.133333\n",
      "snowy  0.000000  0.333333\n",
      "\n",
      "p(w=sunny,t=cold)=0.2\n"
     ]
    }
   ],
   "source": [
    "# Approach 2: Joint distribution using 2D arrays\n",
    "\n",
    "def print_joint_prob_table_array(array, row_labels, col_labels):\n",
    "    \"\"\"\n",
    "    Prints a joint probability table that is stored using the 2D array\n",
    "    representation.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    - array: 2D array for the joint probability table (doesn't have label info)\n",
    "    - row_labels: list of labels; i-th label is for the i-th row in <array>\n",
    "    - col_labels: list of labels; i-th label is for the i-th column in <array>\n",
    "    \"\"\"\n",
    "    if len(array.shape) != 2:\n",
    "        raise Exception(\"The array specified must be two-dimensional.\")\n",
    "    print(pd.DataFrame(array, row_labels, col_labels))\n",
    "    \n",
    "import numpy as np\n",
    "prob_W_T_rows = ['sunny', 'rainy', 'snowy']\n",
    "prob_W_T_cols = ['hot', 'cold']\n",
    "prob_W_T_row_mapping = {label: index for index, label in enumerate(prob_W_T_rows)}\n",
    "prob_W_T_col_mapping = {label: index for index, label in enumerate(prob_W_T_cols)}\n",
    "prob_W_T_array = np.array([[3/10, 1/5], [1/30, 2/15], [0, 1/3]])\n",
    "\n",
    "print(prob_W_T_array, '\\n')\n",
    "\n",
    "print_joint_prob_table_array(prob_W_T_array, prob_W_T_rows, prob_W_T_cols)\n",
    "\n",
    "w = 'sunny'\n",
    "t = 'cold'\n",
    "print(f'\\np(w={w},t={t})={prob_W_T_array[prob_W_T_row_mapping[w], prob_W_T_col_mapping[t]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marganlisation** \n",
    "\n",
    "For two r.vs $X,Y$ with joint probability $p_{X,Y}$  \n",
    "$p_X(x)= \\sum_yp_{X,Y}(x,y)$  - marginalising out $Y$   \n",
    "$p_Y(y)= \\sum_xp_{X,Y}(x,y)$ - marginalising out $X$  \n",
    "\n",
    "\n",
    "For four r.vs $X,Y,Z,W$ with joint probability $p_{X,Y,Z,W}$  \n",
    "$p_{X,Y}(x,y)= \\sum_z\\sum_w p_{X,Y,Z,W}(x,y,z,w)$  - marginalising out $Z$ and $W$\n",
    "\n",
    "In general  \n",
    "\n",
    "$p_{X_1 ... X_{k}}(x_1,...,x_{k})=\\sum_{x_{k+1}}...\\sum_{x_N} p_{X_1,...,X_k,X_{k+1},...,X_N}(x_1,...,x_k, x_{k+1}...,x_N)$\n",
    "\n",
    "Useful anology: summing out rows or columns in a joint probability table.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:25:01.444210Z",
     "start_time": "2020-04-18T09:25:01.437228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot     0.333333\n",
      "cold    0.666667\n",
      "dtype: float64\n",
      "\n",
      "sunny    0.500000\n",
      "rainy    0.166667\n",
      "snowy    0.333333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "prob_T = pd.Series(prob_W_T_array.sum(axis=0), index=prob_W_T_col_mapping.keys())\n",
    "\n",
    "prob_W = pd.Series(prob_W_T_array.sum(axis=1), index=prob_W_T_row_mapping.keys())\n",
    "\n",
    "\n",
    "print(prob_T)\n",
    "\n",
    "print(f'\\n{prob_W}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditioning on Events** \n",
    "\n",
    "Given $(\\Omega, \\mathbb{P})$ (space and probabilities) and event $A$ occurs, we now know $\\omega \\in A$.  \n",
    "So:  \n",
    "$\\Omega \\rightarrow A$ - Space is reduced  \n",
    "$\\mathbb{P} \\rightarrow \\mathbb{P}(\\cdot|A)$  \n",
    "\n",
    "For single element $\\omega$:  \n",
    "$\\mathbb{P}(\\omega|A) = \\begin{cases} 0 \\ \\ \\ \\ \\ \\ \\   w \\notin A \\\\ \\frac{\\mathbb{P}(\\omega)}{\\mathbb{P}(A)}  \\ \\  w \\in A \\end{cases}$\n",
    "\n",
    "$\\sum_{\\omega \\in A} \\mathbb{P}(\\omega|A)=1$  \n",
    "\n",
    "Conditional probability of *event* $B$ given event $A$:   \n",
    "$\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)}$   \n",
    "\n",
    "\n",
    "Product rule for random variables (chain rule; this has $N!$ orderings)    \n",
    "$\n",
    "p_{X_1, ...,  X_N}(x_1,...,x_N) = p_{X_1}(x_1)p_{X_2}(x_2|x_1)p_{X_3}(x_3|x_1, x_2)...p_{X_N}(x_N|x_1...x_{N-1})\n",
    "$  \n",
    "\n",
    "\n",
    "Useful anology: taking a slice of a joint probability table and renormalizing so entries within that slice summed to 1.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:45:10.904416Z",
     "start_time": "2020-04-18T09:45:10.899511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(w=sunny,t=cold)=0.2\n",
      "p(w=sunny|t=cold)=0.3 (p(t=cold)=0.67\n",
      "p(t=cold|w=sunny)=0.4 (p(w=sunny)=0.5\n"
     ]
    }
   ],
   "source": [
    "# Conditional probability\n",
    "\n",
    "w = 'sunny'\n",
    "t = 'cold'\n",
    "print(f'p(w={w},t={t})={prob_W_T_array[prob_W_T_row_mapping[w], prob_W_T_col_mapping[t]]}')\n",
    "print(f'p(w={w}|t={t})={prob_W_T_array[prob_W_T_row_mapping[w], prob_W_T_col_mapping[t]]/ prob_T[t]} (p(t={t})={np.round(prob_T[t],2)}')\n",
    "print(f'p(t={t}|w={w})={prob_W_T_array[prob_W_T_row_mapping[w], prob_W_T_col_mapping[t]]/ prob_W[w]} (p(w={w})={np.round(prob_W[w],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Law of Total Probability**  \n",
    "Useful when you don't have access to all event $A$ but rather to disjoint (partitioned) events $B_i$ that cover the full space.  \n",
    "\n",
    "$\\forall \\ k \\ne l \\ B_k \\cap B_l = \\phi$   (partitioned events)  \n",
    "$\\cup_{i=1}^{n} B_i = \\Omega$  (covers the full space)  \n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A) = \\sum_{i=1}^{n}\\mathbb{P}(A|B_i)\n",
    "$$\n",
    "\n",
    "\n",
    "**Bayes Rule/Theorem for Random Variables**   \n",
    "Given observed $Y=y$:  \n",
    "$$\n",
    "p_{X|Y}(x|y) = \\frac{p_X(x)p_{Y|X}(y|x)}{\\sum_{x'} p_X(x')p_{Y|X}(y|x')}\n",
    "$$\n",
    "\n",
    "\n",
    "**Independence**   $X \\perp \\!\\!\\! \\perp  Y$  \n",
    "\n",
    "$\\mathbb{P}(A\\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$  \n",
    "$\\mathbb{P}(A|B) = \\mathbb{P}(A)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*0.8 + 75*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:13:03.986118Z",
     "start_time": "2020-04-21T06:13:03.976536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      " [[0.5        0.        ]\n",
      " [0.         0.16666667]\n",
      " [0.         0.33333333]]\n",
      "\n",
      "p_W: [0.5        0.16666667 0.33333333]\n",
      "p_I: [0.5 0.5]\n",
      "\n",
      "output\n",
      " [[0.25       0.25      ]\n",
      " [0.08333333 0.08333333]\n",
      " [0.16666667 0.16666667]]\n",
      "\n",
      " input=output (i.e, X, Y independent)?: False\n"
     ]
    }
   ],
   "source": [
    "# Testing for independence\n",
    "import numpy as np\n",
    "\n",
    "# W and I are dependent\n",
    "prob_W_I = np.array([[1/2, 0], [0, 1/6], [0, 1/3]])\n",
    "\n",
    "# W and I are independent\n",
    "#prob_W_I = np.array([[1/4, 1/4], [1/12, 1/12], [1/6, 1/6]])\n",
    "\n",
    "prob_W = prob_W_I.sum(axis=1)\n",
    "prob_I = prob_W_I.sum(axis=0)\n",
    "\n",
    "print('input\\n',prob_W_I)\n",
    "print('\\np_W:', prob_W)\n",
    "print('p_I:',prob_I)\n",
    "prob_W_outer_prob_I = np.outer(prob_W, prob_I)\n",
    "print('\\noutput\\n',prob_W_outer_prob_I)\n",
    "\n",
    "print(f'\\n input=output (i.e, X, Y independent)?: {np.allclose(prob_W_outer_prob_I, prob_W_I)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T05:29:04.604118Z",
     "start_time": "2020-04-21T05:29:04.534787Z"
    }
   },
   "source": [
    "The `np.outer` does the following:  \n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cc}\n",
    "p_W(\\text{sunny}) \\\\\n",
    "p_W(\\text{rainy}) \\\\\n",
    "p_W(\\text{snowy}) \n",
    "\\end{array} \\right)\n",
    "%\n",
    "\\left( \\begin{array}{cc}\n",
    "p_I(0) &\n",
    "p_I(1) \\\\\n",
    "\\end{array} \\right) = \n",
    "%\n",
    "\\left( \\begin{array}{cc}\n",
    "p_W(\\text{sunny})p_I(0) & p_W(\\text{sunny})p_I(1) \\\\\n",
    "p_W(\\text{rainy})p_I(0) & p_W(\\text{rainy})p_I(1) \\\\\n",
    "p_W(\\text{snowy})p_I(0) & p_W(\\text{snowy})p_I(1) \\\\\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual vs Pairwise Independence**  \n",
    "Mutual independence is also called *Marginal independence*.  \n",
    "$X, Y, Z$ are mutually independent if      \n",
    "$p_{X,Y,Z}(x,y,z)=p_X(x)p_Y(y)p_Z(z)$  \n",
    "In words: knowing any r.v means we do not know anything about any other.  \n",
    "\n",
    "Pariwise independence - a weaker form of indpendence   \n",
    "$p_{X,Y}(x,y)=p_X(x)p_Y(y)$    (for any pair combination of the three)  \n",
    "In words: knowing a pair of r.v means we do not know anything about the third.  \n",
    "\n",
    "Example: XOR function  \n",
    "$X,Y$ are independent r.v where $Z=X\\oplus Y$\n",
    "\n",
    "|$X$|$Y$|$Z$|\n",
    "|------|------|------|\n",
    "|0|0|0|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|0|  \n",
    "\n",
    "We see   \n",
    "$p_Z(z) =  \\begin{cases} 0.5 \\ \\ z=0 \\\\ 0.5 \\ \\ z=1 \\end{cases}$  \n",
    "which equals $p_{Z|X}(z|x)$ and $p_{Z|Y}(z|y)$.   \n",
    "Meaning \n",
    "* pairwise independence: $X \\perp \\!\\!\\! \\perp  Y$, $X \\perp \\!\\!\\! \\perp  Z$, $Z \\perp \\!\\!\\! \\perp  Y$  \n",
    "* not mutual indpendence! $p_{Z|X,Y}(z|x,y) \\ne p_Z(z)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Independence**\n",
    "\n",
    "$$p_{X,Y|Z}(x,y|z) = p_{X|Z}(x|z)p_{Y|Z}(y|z)$$\n",
    "\n",
    "Conditional Independence does not lead to Marginal independence and vice versa.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum A Posteriori (MAP) Estimation**   \n",
    "When we want to report wthe most probable value $𝑥$ that $𝑋$ can take on given that we have observed $𝑌=𝑦$. In general there might be multiple values.    \n",
    "$$\n",
    "\\hat{x} = \\text{arg max}_x p_{X|Y}(x|y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pY|X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>X</th>\n",
       "      <th>healthy</th>\n",
       "      <th>infected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "X  healthy  infected\n",
       "Y                   \n",
       "+     0.01      0.99\n",
       "-     0.99      0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(-|healthy) = 0.99999\n",
      "p(+|healthy) = 0.90984\n",
      "p(-|infected) = 1e-05\n",
      "p(+|infected) = 0.09016\n"
     ]
    }
   ],
   "source": [
    "# Bayes' Theorem for Random Variables: Medical Diagnosis\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pX = {'healthy': 0.999, 'infected': 0.001}\n",
    "pY_givenX = {'healthy':{'+':0.01, '-':0.99}, 'infected':{'+': 0.99, '-':0.01}}\n",
    "\n",
    "print('pY|X')\n",
    "df = pd.DataFrame(pY_givenX)\n",
    "df.index.name = 'Y'\n",
    "df.columns.name = 'X'\n",
    "display(df)\n",
    "\n",
    "x_to_not = {'healthy': 'infected', 'infected': 'healthy'}\n",
    "for x in pX.keys():\n",
    "    x_not = x_to_not[x]\n",
    "    for y in ['-', '+']:\n",
    "        pX_givenY = pY_givenX[x][y] * pX[x] / (pY_givenX[x][y] * pX[x] + pY_givenX[x_not][y] * pX[x_not])\n",
    "        print(f'p({y}|{x}) = {np.round(pX_givenY,5)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions\n",
    "\n",
    "**Cumulative Probability**\n",
    "\n",
    "The cumulative distribution function of real-valued random variable $X$ evaluated at $x$  is the probability that $X$ will take a value less than or equal to $x$:\n",
    "$$\n",
    "F_X(x) = P(X\\le x)\n",
    "$$\n",
    "\n",
    "also\n",
    "$$\n",
    "P(a \\le X\\le b) = F_X(b)- F_X(a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernouli/Binomial \n",
    "\n",
    "### Binomial Experiment\n",
    "Also called Bernoulli trial\n",
    "\n",
    "A statistical experiment that has the following properties:  \n",
    "* The experiment consists of  repeated trials.\n",
    "* The trials are independent.\n",
    "* The outcome of each trial is either success ($s$) or failure ($f$).\n",
    "\n",
    "### Binomial Distribution \n",
    "Also called Bernouli \n",
    "\n",
    "The probability distribution of $k$  successes in $n$ independent Bernoulli experiments, each with probability of success $p$. \n",
    "\n",
    "Probability mass function:\n",
    "$$\n",
    "b(k,n,p) = {n \\choose k} p^k (1-p)^{(n-k)}\n",
    "$$\n",
    "\n",
    "It is often used to model the number successes in sample size ***with replacement*** from a population size $N$ (for without replacement see [Hypergeometric Distribution](#Hypergeometric-Distribution))\n",
    "\n",
    "**Bernouli Distribution**  \n",
    "Is a specific case of Binomial of $b(k,1,p)$ where $k=0,1$.\n",
    "\n",
    "Probability mass function:\n",
    "$$\n",
    "b(k,1,p) = {1 \\choose k} p^k (1-p)^{(1-k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:59:28.203564Z",
     "start_time": "2020-03-18T14:59:28.196740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24609375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "# probability of k successes in n trials\n",
    "p = 0.5\n",
    "n = 10\n",
    "k = 5\n",
    "\n",
    "comb(n, k) * (p**k) * ( (1-p)**(n-k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T15:00:45.174695Z",
     "start_time": "2020-03-18T15:00:45.165581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.623046875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = 0  # probability of having k successes within ks of n trials\n",
    "\n",
    "#ks = [5, 6, 7, 8, 9, 10]\n",
    "ks = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "for k in ks:\n",
    "    pp += comb(n, k) * (p**k) * ( (1-p)**(n-k))\n",
    "    \n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Geometric Distribution \n",
    "One of two descrete distributions:\n",
    "* The probability distribution of the number $X$ of Bernoulli trials needed to get one success, supported on the set $k = \\{1, 2, 3, ... \\}$.\n",
    "\n",
    "$$\n",
    "Pr(X=k) = (1-p)^{k-1}p, \\ \\ \\ \\ \\ \\text{for} \\ k=1,2,3...\n",
    "$$\n",
    "\n",
    "* The probability distribution of the number $Y = X − 1$ of failures before the first success, supported on the set $k = \\{ 0, 1, 2, ... \\}$\n",
    "$$\n",
    "Pr(Y=k) = (1-p)^kp, \\ \\ \\ \\ \\ \\text{for} \\ k=0,1,2,...\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Which of these one calls \"the\" geometric distribution is a matter of convention and convenience.\n",
    "\n",
    "In either case, the sequence of probabilities is a geometric sequence (i.e, $r^k$)\n",
    "\n",
    "**Requirements**  \n",
    "* The phenomenon being modeled is a sequence of independent trials.\n",
    "* There are only two possible outcomes for each trial, often designated success or failure.\n",
    "* The probability of success, $p$, is the same for every trial.\n",
    "\n",
    "\n",
    "**Related**    \n",
    "Negative Binomial Experiment,  Negative Binomial Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:45:57.806542Z",
     "start_time": "2020-03-18T14:45:57.781987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1/2. # probability of giving birth to a girl\n",
    "\n",
    "# probability of giving birth to a girl on the 4th try\n",
    "k = 4  \n",
    "print((1-p)**(k-1)*p)\n",
    "\n",
    "# probability of having 3 boys before the first girl\n",
    "k = 3\n",
    "(1-p)**k * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T14:53:50.206569Z",
     "start_time": "2020-03-18T14:53:50.198745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8683127572016461\n",
      "0.868312757201646\n"
     ]
    }
   ],
   "source": [
    "p = 1./3  # probability of failing an inspection\n",
    "\n",
    "pp = 0    # What is the probability that the 1st defect is found during the first 5 inspections?\n",
    "\n",
    "max_k = 5\n",
    "for k in range(0, max_k):\n",
    "    pp += (1-p)**k * p    \n",
    "\n",
    "print(pp)\n",
    "\n",
    "# better method (imagine max_k>1000)\n",
    "pp_inv = (1-p)**max_k # probablity that passing inspection in all 5 inspections\n",
    "print(1- pp_inv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypergeometric Distribution\n",
    "\n",
    "The probability of sampling ***without replacement*** $k$ successes in a sample of $n$ from a population of total $N$ and $K$ total successes.\n",
    "\n",
    "Probability Mass Function:\n",
    "$$\n",
    "P(X=k) = \\frac{ {K \\choose k} { {N-K} \\choose {n-k} } }{N \\choose n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T09:59:09.125756Z",
     "start_time": "2020-03-20T09:59:09.118547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10812795900674416\n",
      "0.1081279590067445\n"
     ]
    }
   ],
   "source": [
    "# Example: extracting balls from an urn, \n",
    "# where the balls are either green (success) or red. \n",
    "from scipy.special import comb\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "N=100  # total balls\n",
    "K=60   # red balls\n",
    "n=10   # choosing total 10 balls\n",
    "k=4    # of which are red\n",
    "\n",
    "print(comb(K,k) * comb(N-K, n-k) / comb(N,n))\n",
    "print(hypergeom.pmf(k, N, K, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Distribution\n",
    "Popular for modeling the number of times an event occurs in an interval of time or space.\n",
    "\n",
    "A discrete random variable $X$ is said to have a Poisson distribution with parameter $λ > 0$ (need not be integer), if, for $k = 0, 1, 2, ...,$ the probability mass function of $X$ is given by:  \n",
    "$$\n",
    "P(X=k) = \\frac{\\lambda^ke^{-\\lambda}}{k!}\n",
    "$$\n",
    "\n",
    "$\\lambda$ is both the mean and the variance of the distribution.  \n",
    "$\\lambda=E(X)=V(X)$ \n",
    "\n",
    "[scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T10:11:53.239064Z",
     "start_time": "2020-03-20T10:11:53.233329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03783327480207071\n",
      "0.03783327480207079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import factorial\n",
    "from scipy.stats import poisson \n",
    "\n",
    "lmbda = 10 # mean (and variance) of people entring a store in an hour\n",
    "k = 5 \n",
    "\n",
    "# probability that k people enter the store in an hour\n",
    "print((lmbda ** k) * np.exp(-lmbda) / factorial(k))\n",
    "print(poisson.pmf(k, lmbda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T10:28:12.544777Z",
     "start_time": "2020-03-20T10:28:12.516208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbd_A = 0.88\n",
    "#cost_A = 160 + 40*(X**2)\n",
    "lmbd_B = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution\n",
    "(or Gaussian or Gauss or Laplace–Gauss)\n",
    "\n",
    "A type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is:  \n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{- \\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n",
    "$$\n",
    "\n",
    "* $\\mu$ mean (median and mode)\n",
    "* $\\sigma$ standard deviation ($\\sigma^2$ is the distribution variance)\n",
    "\n",
    "**Standard Normal Distribution**  \n",
    "Case were $f(\\mu=0, \\sigma=1)$\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{- \\frac{1}{2} x^2}\n",
    "$$\n",
    "\n",
    "Conversion  \n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma} \\phi \\left(\\frac{x-\\mu}{\\sigma} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "The Cumulative distribution function is\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{x-\\mu}{\\sigma \\sqrt{2}}\\right)\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{erf}(z) = \\frac{2}{\\sqrt{\\pi} }\\int_{0}^{z} e^{-x^2} dx\n",
    "$$\n",
    "\n",
    "[math.erf](https://docs.python.org/3/library/math.html#math.erf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:44:46.556815Z",
     "start_time": "2020-03-20T11:44:46.549368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4012936743170763"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import erf, sqrt\n",
    "\n",
    "def phi(x):\n",
    "    'Cumulative distribution function for the standard normal distribution'\n",
    "    return (1.0 + erf(x / sqrt(2.0))) / 2.0\n",
    "\n",
    "def cumulative_norm(x, mu=0, sigma=1):\n",
    "    z = (x-mu)/sigma\n",
    "    \n",
    "    return phi(z)\n",
    "\n",
    "\n",
    "cumulative_norm(19.5, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T11:52:38.141231Z",
     "start_time": "2020-03-20T11:52:38.134314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544997361036416"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cumulative_difference(x2, x1, mu=0, sigma=1):\n",
    "    return cumulative_norm(x2, mu, sigma) - cumulative_norm(x1, mu, sigma)\n",
    "\n",
    "mu = 20\n",
    "sigma = 10\n",
    "nsigma = 2\n",
    "\n",
    "cumulative_difference(mu + nsigma*sigma, mu - nsigma*sigma, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:04:30.324473Z",
     "start_time": "2020-03-22T08:04:30.306449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10045"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 9800\n",
    "mu = 205\n",
    "sigma = 15\n",
    "n = 49\n",
    "\n",
    "n*mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:20:12.719202Z",
     "start_time": "2020-03-22T08:20:12.708762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.0 20.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6915"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 250\n",
    "mu = 2.4\n",
    "sigma=2.\n",
    "n = 100\n",
    "\n",
    "mu_ = mu * n\n",
    "sigma_ = sigma * sqrt(n)\n",
    "\n",
    "print(mu_, sigma_)\n",
    "\n",
    "round(cumulative_norm(x, mu_, sigma_),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:36:49.917263Z",
     "start_time": "2020-03-22T08:36:49.890021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484.32\n",
      "515.68\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "mu = 500\n",
    "sigma = 80\n",
    "z = 1.96\n",
    "\n",
    "sigma_ = sigma/sqrt(n)\n",
    "\n",
    "print(round(mu - z * sigma_,2))\n",
    "print(round(mu + z * sigma_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:25:10.824913Z",
     "start_time": "2020-03-22T08:25:10.819081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51568.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_ + z * sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:09:45.144789Z",
     "start_time": "2020-03-22T08:09:45.135032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0098"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "mu_ = n*mu\n",
    "sigma_ = sigma*sqrt(n)\n",
    "\n",
    "mu_, sigma_\n",
    "\n",
    "round(cumulative_norm(x, mu_, sigma_),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:11:45.390717Z",
     "start_time": "2020-03-22T08:11:45.380001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15865525393145707"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, sigma = 70, 10\n",
    "x = 80\n",
    "\n",
    "1. - cumulative_norm(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "* Computational Probability and Inference course [(edX/MIT)](https://www.edx.org/course/computational-probability-and-inference)\n",
    "* Towards Data Science ([Jonny Brooks-Bartlett](https://towardsdatascience.com/@jonnybrooks04))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "177.6px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
